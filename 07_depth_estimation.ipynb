{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ce09e73",
   "metadata": {},
   "source": [
    "# Monocular depth estimation\n",
    "\n",
    "Monocular depth estimation is a computer vision task that involves predicting the depth information of a scene from a single image. In other words, it is the process of estimating the distance of objects in a scene from a single camera viewpoint.\n",
    "\n",
    "Monocular depth estimation has various applications, including 3D reconstruction, augmented reality, autonomous driving, and robotics. It is a challenging task as it requires the model to understand the complex relationships between objects in the scene and the corresponding depth information, which can be affected by factors such as lighting conditions, occlusion, and texture.\n",
    "\n",
    "There are two main depth estimation categories:\n",
    "\n",
    "Absolute depth estimation: This task variant aims to provide exact depth measurements from the camera's perspective. The term is used interchangeably with metric depth estimation, where depth is provided in precise measurements in meters or feet. Absolute depth estimation models output depth maps with numerical values that represent real-world distances.\n",
    "\n",
    "Relative depth estimation: Relative depth estimation aims to predict the depth order of objects or points in a scene without providing the precise measurements. These models output a depth map that indicates which parts of the scene are closer or farther relative to each other without the actual distances to A and B.\n",
    "\n",
    "In this guide, we will see how to:\n",
    "1. Infer relative depth using Depth Anything V2, a state-of-the-art zero-shot relative depth estimation model.\n",
    "2. Infer depth estimation using ZoeDepth, an absolute depth estimation model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1680fcc9",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89372bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -q -U transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6581a30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import requests\n",
    "from PIL import Image\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249b0a5f",
   "metadata": {},
   "source": [
    "# Depth estimation via HF pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9fbdc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load checkpoint and send computation to GPU if available\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "checkpoint = \"depth-anything/Depth-Anything-V2-base-hf\"\n",
    "pipe = pipeline(\"depth-estimation\", model=checkpoint, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a072fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load image for analysis\n",
    "url = \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/bee.jpg\"\n",
    "image = Image.open(requests.get(url, stream=True).raw)\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4596f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass the image to the pipeline\n",
    "# The pipeline returns a dictionary with two entries: predicted_depth and depth\n",
    "# predicted_depth is a tensor with the values being the depth expressed in meters for each pixel\n",
    "# depth is a PIL image that visualizes the depth estimation result\n",
    "predictions = pipe(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab65f081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise the prediction\n",
    "predictions[\"depth\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nlp]",
   "language": "python",
   "name": "conda-env-nlp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
