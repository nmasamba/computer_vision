{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9a3e079",
   "metadata": {},
   "source": [
    "Object detection is the computer vision task of detecting instances (such as humans, buildings, or cars) in an image. Object detection models receive an image as input and output coordinates of the bounding boxes and associated labels of the detected objects. An image can contain multiple objects, each with its own bounding box and a label (e.g. it can have a car and a building), and each object can be present in different parts of an image (e.g. the image can have several cars). This task is commonly used in autonomous driving for detecting things like pedestrians, road signs, and traffic lights. Other applications include counting objects in images, image search, and more.\n",
    "\n",
    "This guide shows how to:\n",
    "1. Finetune DETR, a model that combines a convolutional backbone with an encoder-decoder Transformer, on the CPPE-5 dataset.\n",
    "2. Use your finetuned model for inference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0a9efa",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89372c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -q datasets transformers accelerate timm\n",
    "pip install -q -U albumentations>=1.4.5 torchmetrics pycocotools # use albumentations to augment the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cec390b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65f56c2",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3bb105c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the conditional DETR model due to its faster convergence\n",
    "MODEL_NAME = \"microsoft/conditional-detr-resnet-50\"  # or \"facebook/detr-resnet-50\"\n",
    "IMAGE_SIZE = 480"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb36bf5",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5615cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The CPPE-5 dataset contains images with annotations identifying medical personal protective equipment (PPE)\n",
    "# in the context of the COVID-19 pandemic\n",
    "cppe5 = load_dataset(\"cppe-5\")\n",
    "\n",
    "if \"validation\" not in cppe5:\n",
    "    split = cppe5[\"train\"].train_test_split(0.15, seed=1337)\n",
    "    cppe5[\"train\"] = split[\"train\"]\n",
    "    cppe5[\"validation\"] = split[\"test\"]\n",
    "\n",
    "cppe5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nlp]",
   "language": "python",
   "name": "conda-env-nlp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
